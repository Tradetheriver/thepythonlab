{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La importancia del formato pickle en pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las ventajas de los formatos .pickle, frente a cualquier otro formato, para mi son evidentes. Somos personas, que necesitamos abrir muchos datos, tratarlos, manipularlos, crear nuevos campos, y luego debemos poder guardarlo.   \n",
    "Por consecuencia, vamos a realizar unas pruebas, para ver que formato nos conviene mas utilizar.  \n",
    "Supongamos que estamos en un universo perfecto, donde nos entregan  el dataset ya preprocesado, y en un perfecto order en un archivo .csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un tiempo rapido de carga, pero claro, un archivo, y ya preprocesado, todos sabemos que los datos nunca suelen llegar de esta manera  \n",
    "Pero bueno, hagamos trampas al solitario y pensemos que si....  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 491 ms\n"
     ]
    }
   ],
   "source": [
    "%time import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.87 s\n"
     ]
    }
   ],
   "source": [
    "%time data = pd.read_csv('C1500000 Sales Records.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500000, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale, hemos cargado un dataset de unos 200mb, en menos de 3 segundos. Â¿ Que mas podemos pedir ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%time data.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos, que ya nos vamos a 20 segundos en pasar nuestro dataframe a csv, sin ni siquiera tocarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La opcion de los xlsx, es la peor de todas con diferencia. Aunque es la favorita de muchos ;). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 53s\n"
     ]
    }
   ],
   "source": [
    "%time data.to_excel(\"data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%time excel = pd.read_excel(\"data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a probar con los .pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%time data.to_pickle(\"data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 763 ms\n"
     ]
    }
   ],
   "source": [
    "%time pickle = pd.read_pickle(\"data.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto quiero justificar el uso de pickle en todos los notebooks, a todos nos llegan los datos de multitud de fuentes, cada una con sus caracteristicas concretas,\n",
    "y nos toca pasar por arduos procesos, para poder tener un dataframe con nuestra informacion. Pues ahorraremos estos procesos en el futuro, ademas de agilizar el trabajo, con una carga o escritura mas rapida de ficheros.  \n",
    "Por mi experiencia particular, para cargar datos de opciones financieras,es una ardua tarea de ficheros de 200mb por dia, y como queramos cargar un historico medio razonable,  \n",
    "se pueden ir a procesos de hasta 20h. Luego lo volcamos todo en un pickle, y no tardamos ni un segundo para estar funcionando.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
